{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JNv7BE_HRi"
      },
      "source": [
        "from requests import get\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import sleep\n",
        "from random import randint\n",
        "import re\n",
        "import unicodedata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_v5yf_LjdaA"
      },
      "source": [
        "#funções úteis\n",
        "\n",
        "def reject_outliers(data, m=2):\n",
        "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWzf-3zQ-xu6"
      },
      "source": [
        "#Criando Database de idiomas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlBtE24zhyz1"
      },
      "source": [
        "#Essa célula extrai os idiomas disponíveis para digitação e escolhe os 10 idiomas mais relevantes para estudo\n",
        "\n",
        "response = get('https://www.keyhero.com/typing-statistics/')\n",
        "html_soup = BeautifulSoup(response.text,'html.parser')\n",
        "languages_table = html_soup.find('table', class_ = 'table table-striped table-condensed table-bordered')\n",
        "\n",
        "df_lang = pd.DataFrame(columns = ['Name', 'Number of Quotes', 'Link'])\n",
        "\n",
        "for language in languages_table.find_all('tr')[1:]:\n",
        "  name = language.a.text\n",
        "  num_quotes = language.find(class_='text-right').text\n",
        "  link = language.a['href']\n",
        "  df_lang = df_lang.append({'Name': name, 'Number of Quotes' : int(num_quotes), 'Link' : link}, ignore_index=True)\n",
        "\n",
        "#Ordena pela quantidade de citações disponíveis para cada idioma em ordem decrescente\n",
        "df_lang = df_lang.sort_values('Number of Quotes',  ascending=False)\n",
        "\n",
        "#Pega os 10 idiomas com maior número de citações públicadas\n",
        "df_lang = df_lang.iloc[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTzSkgyf_b9h",
        "outputId": "8304d5f0-403c-441a-d0cb-71d070ff7762"
      },
      "source": [
        "print(df_lang)\n",
        "df_lang.to_csv(\"langs.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             Name Number of Quotes        Link\n",
            "3                         English            22433   /quotes/0\n",
            "24              Español (Spanish)             1979   /quotes/2\n",
            "8               Français (French)             1102   /quotes/1\n",
            "16               Türkçe (Turkish)              583  /quotes/21\n",
            "1               Svenska (Swedish)              304   /quotes/5\n",
            "15         Português (Portuguese)              241   /quotes/3\n",
            "11               Deutsch (German)              209   /quotes/6\n",
            "19                Polish (Polski)              197  /quotes/16\n",
            "12             Italian (Italiano)              186   /quotes/4\n",
            "21  Bahasa Indonesia (Indonesian)              156   /quotes/7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXOTsJno-2LF"
      },
      "source": [
        "#Extraindo Citações de cada um dos Idiomas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbZUwwhYjZIp"
      },
      "source": [
        "#Para cada um dos 10 idiomas extraimos 60 citações\n",
        "\n",
        "df_quotes = pd.DataFrame(columns = ['Idx', 'Lang'])\n",
        "\n",
        "for _, lang in df_lang.iterrows():\n",
        "  lang_link = lang['Link']\n",
        "  lang_name = lang['Name']\n",
        "  url = 'https://www.keyhero.com/' + lang_link + '?best&page='\n",
        "  for i in range(1, 4):\n",
        "    response = get(url + str(i))\n",
        "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    for quote in html_soup.find_all('div' , class_ = 'rating-block'):\n",
        "      m = re.match(r\"^rating(\\w+)\", quote['id'])\n",
        "      idx = int(m[1])\n",
        "      df_quotes = df_quotes.append({'Idx': idx, 'Lang' : lang_name}, ignore_index=True)\n",
        "    sleep(randint(1,3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd8UMtCaAVI6",
        "outputId": "1008d96f-4f80-4679-cb0a-ead3676975bc"
      },
      "source": [
        "print(df_quotes)\n",
        "df_quotes.to_csv(\"quotes.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Idx                           Lang\n",
            "0    17695                        English\n",
            "1    15052                        English\n",
            "2    11520                        English\n",
            "3     4764                        English\n",
            "4    14667                        English\n",
            "..     ...                            ...\n",
            "595  13604  Bahasa Indonesia (Indonesian)\n",
            "596  13291  Bahasa Indonesia (Indonesian)\n",
            "597  13292  Bahasa Indonesia (Indonesian)\n",
            "598  13601  Bahasa Indonesia (Indonesian)\n",
            "599  13605  Bahasa Indonesia (Indonesian)\n",
            "\n",
            "[600 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNolTx4t_Kpm"
      },
      "source": [
        "#Extraindo mais dados sobre cada citação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wuRTRqp7piL"
      },
      "source": [
        "# Função para fazer request de uma página de citação a partir do index da citação\n",
        "def request_quote_page(index):\n",
        "    # Requisição da pagina\n",
        "    url = 'https://www.keyhero.com/online-typing-test/' + index + '/'\n",
        "    response = get(url)\n",
        "\n",
        "    # Parsing\n",
        "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return html_soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NbiDBS-7yDO"
      },
      "source": [
        "def scrap_quote_page(html_soup):\n",
        "    # Pegando citação\n",
        "    quote_container = html_soup.find('div', class_ = 'quoteinfo')\n",
        "        # .next_sibling => a citação não se encontra no quoteinfo, mas logo em seguida\n",
        "        # .strip() => pega somente a citação, sem isso possui quebra de linha e espaçamento\n",
        "    quote = quote_container.next_sibling.strip()\n",
        "    title = html_soup.find('h3').text\n",
        "\n",
        "    # Pegando estatísticas\n",
        "    statistics_container = html_soup.find_all('table')\n",
        "    wpm_top = []\n",
        "    acc_top = []\n",
        "    wpm_new = []\n",
        "    acc_new = []\n",
        "\n",
        "    # Pegando melhores\n",
        "    for row in statistics_container[0].find_all('tr'):\n",
        "        if(row.find('td', class_ = 'text-right')):\n",
        "            wpm_top.append(row.find_all('td', class_ = 'text-right')[0].text)\n",
        "            acc_top.append(row.find_all('td', class_ = 'text-right')[1].text)\n",
        "\n",
        "    # Pegando mais recentes\n",
        "    for row in statistics_container[1].find_all('tr'):\n",
        "        if(row.find('td')):\n",
        "            wpm_new.append(row.find_all('td')[1].text)\n",
        "            acc_new.append(row.find_all('td')[2].text)\n",
        "\n",
        "    # Corrigindo as listas\n",
        "        # Retira o %\n",
        "    acc_top = [x[:-1] for x in acc_top] \n",
        "    acc_new = [x[:-1] for x in acc_new]\n",
        "        # Transforma em lista de floats\n",
        "    wpm_top = list(map(float, wpm_top)) \n",
        "    wpm_new = list(map(float, wpm_new))\n",
        "    acc_top = list(map(float, acc_top))\n",
        "    acc_new = list(map(float, acc_new))\n",
        "\n",
        "    #Removendo os outliers de wpm (possíveis bots com uma pontuação muito superior)\n",
        "    wpm_top = reject_outliers(np.array(wpm_top))\n",
        "    wpm_new = reject_outliers(np.array(wpm_new))\n",
        "    # Calculando as médias\n",
        "    wpm_top_average = np.mean(wpm_top)\n",
        "    acc_top_average = np.mean(acc_top)\n",
        "    wpm_new_average = np.mean(wpm_new)\n",
        "    acc_new_average = np.mean(acc_new)\n",
        "\n",
        "    new_row = pd.DataFrame(data = [[title, quote, wpm_top_average, acc_top_average, wpm_new_average, acc_new_average]], columns = ['title', 'quote', 'average_wpm_top', 'average_acc_top', 'average_wpm_new', 'average_acc_new'])\n",
        "    return new_row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzoZ7GhRiNbm"
      },
      "source": [
        "# Criando dataset\n",
        "dataset = pd.DataFrame(columns = ['title', 'quote', 'average_wpm_top', 'average_acc_top', 'average_wpm_new', 'average_acc_new'])\n",
        "\n",
        "#Criando database de citações\n",
        "counter = 0\n",
        "for index in df_quotes['Idx']:\n",
        "    counter += 1\n",
        "    print(counter)\n",
        "    html_soup = request_quote_page(str(index))\n",
        "    new_row = scrap_quote_page(html_soup)\n",
        "    dataset = dataset.append(new_row, ignore_index = True)\n",
        "    #espera de 1 a 3 segundos entre um request e outro\n",
        "    sleep(randint(1,3))\n",
        "\n",
        "dataset['idioma'] = df_quotes['Lang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOAvjqmuk2CJ",
        "outputId": "03a9eb01-d878-414b-b74c-c624ccaf0547"
      },
      "source": [
        "print(dataset)\n",
        "dataset.to_csv('dataset.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 title  ...                         idioma\n",
            "0                 How important you are. - Fred Rogers  ...                        English\n",
            "1                                Alexander Graham Bell  ...                        English\n",
            "2                                Forgive - Brian Weiss  ...                        English\n",
            "3                              Martin Luther King, Jr.  ...                        English\n",
            "4                                     Power - Bob Ross  ...                        English\n",
            "..                                                 ...  ...                            ...\n",
            "595           Bunga Kebun Tanjong - Muhammad Nasir Age  ...  Bahasa Indonesia (Indonesian)\n",
            "596  Suamiku Jatuh Cinta Pada Jam Dinding - Arswend...  ...  Bahasa Indonesia (Indonesian)\n",
            "597  Suamiku Jatuh Cinta Pada Jam Dinding - Arswend...  ...  Bahasa Indonesia (Indonesian)\n",
            "598                   Tandan Sawit - Nafi'ah Al-Ma'rab  ...  Bahasa Indonesia (Indonesian)\n",
            "599           Bunga Kebun Tanjong - Muhammad Nasir Age  ...  Bahasa Indonesia (Indonesian)\n",
            "\n",
            "[600 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_VOeozo8zJA"
      },
      "source": [
        "#Extração de informações textuais das Citações\n",
        "\n",
        "* Quantidade de caracteres (tamanho do texto)\n",
        "* Extrair tamanho médio das palavras. \n",
        "* Quantidade de letras maiúsculas\n",
        "* Quantidade de caracteres não alfanuméricos (expandir o conceito de alfanumérico para aceitar caracteres de outras línguas, como o turco)\n",
        "* Quantidade de acentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Up80_wa990_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30887258-1262-454b-ab08-d9a4b0030f03"
      },
      "source": [
        "dataset_inicial = pd.read_csv(\"dataset.csv\", index_col = 0)\n",
        "print(dataset_inicial)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 title  ...                         idioma\n",
            "0                 How important you are. - Fred Rogers  ...                        English\n",
            "1                                Alexander Graham Bell  ...                        English\n",
            "2                                Forgive - Brian Weiss  ...                        English\n",
            "3                              Martin Luther King, Jr.  ...                        English\n",
            "4                                     Power - Bob Ross  ...                        English\n",
            "..                                                 ...  ...                            ...\n",
            "595           Bunga Kebun Tanjong - Muhammad Nasir Age  ...  Bahasa Indonesia (Indonesian)\n",
            "596  Suamiku Jatuh Cinta Pada Jam Dinding - Arswend...  ...  Bahasa Indonesia (Indonesian)\n",
            "597  Suamiku Jatuh Cinta Pada Jam Dinding - Arswend...  ...  Bahasa Indonesia (Indonesian)\n",
            "598                   Tandan Sawit - Nafi'ah Al-Ma'rab  ...  Bahasa Indonesia (Indonesian)\n",
            "599           Bunga Kebun Tanjong - Muhammad Nasir Age  ...  Bahasa Indonesia (Indonesian)\n",
            "\n",
            "[600 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZO0Gcwl1C4u"
      },
      "source": [
        "def info_from_quote(quote):\n",
        "  words = re.findall(r\"\\w+(?:'\\w)?\\w*\", quote, re.UNICODE)\n",
        "  nfkd_form = unicodedata.normalize('NFKD', quote)\n",
        "\n",
        "  length = len(quote)\n",
        "  avg_word_len = (float(sum([len(w) for w in words])) / len(words))\n",
        "  upper_case = sum(1 for c in quote if c.isupper())\n",
        "  not_alpha = len(re.findall(r'[^\\w\\s]', quote))\n",
        "  accent = sum(map(lambda c: 1 if (unicodedata.combining(c) != 0) else 0, nfkd_form))\n",
        "\n",
        "  return length, avg_word_len, upper_case, not_alpha, accent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9QoeHfu6tEp",
        "outputId": "65ee222b-630a-425c-958a-5d57a3a5b4f9"
      },
      "source": [
        "length = []\n",
        "avg_word_len = []\n",
        "upper_case = []\n",
        "not_alpha = []\n",
        "accent = []\n",
        "\n",
        "for quote in dataset_inicial['quote']:\n",
        "    ret = info_from_quote(quote)\n",
        "    length.append(ret[0])\n",
        "    avg_word_len.append(ret[1])\n",
        "    upper_case.append(ret[2])\n",
        "    not_alpha.append(ret[3])\n",
        "    accent.append(ret[4])\n",
        "\n",
        "dataset_inicial['length'] = length\n",
        "dataset_inicial['avg_word_len'] = avg_word_len\n",
        "dataset_inicial['upper_case'] = upper_case\n",
        "dataset_inicial['not_alpha'] = not_alpha\n",
        "dataset_inicial['accent'] = accent\n",
        "\n",
        "print(dataset_inicial)\n",
        "dataset_inicial.to_csv(\"dataset_final.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 title  ... accent\n",
            "0                 How important you are. - Fred Rogers  ...      0\n",
            "1                                Alexander Graham Bell  ...      0\n",
            "2                                Forgive - Brian Weiss  ...      0\n",
            "3                              Martin Luther King, Jr.  ...      0\n",
            "4                                     Power - Bob Ross  ...      0\n",
            "..                                                 ...  ...    ...\n",
            "595           Bunga Kebun Tanjong - Muhammad Nasir Age  ...      0\n",
            "596  Suamiku Jatuh Cinta Pada Jam Dinding - Arswend...  ...      0\n",
            "597  Suamiku Jatuh Cinta Pada Jam Dinding - Arswend...  ...      0\n",
            "598                   Tandan Sawit - Nafi'ah Al-Ma'rab  ...      0\n",
            "599           Bunga Kebun Tanjong - Muhammad Nasir Age  ...      0\n",
            "\n",
            "[600 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}